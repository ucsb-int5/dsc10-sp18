{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Warplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serialno = Table().with_column('Serial number', np.arange(1, 301))\n",
    "\n",
    "repetitions = 1000\n",
    "sample_size = 30\n",
    "doubles_mean = make_array()\n",
    "max_array = make_array()\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    sample = serialno.sample(sample_size).column(0)\n",
    "    max_array = np.append(max_array, np.max(sample))\n",
    "    doubles_mean = np.append(doubles_mean, np.mean(sample)*2)\n",
    "\n",
    "estimates = Table().with_columns(\"2*mean\", doubles_mean, 'max', max_array)\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.hist(bins = np.arange(1, 400, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we come up with a new estimate that's less biased than the largest number seen, and less variable than twice the average?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jury selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 felony trials and 1453 people who reported for jury service\n",
    "# Looked at the ethnic composition of those 1453 people\n",
    "# as compared to the ethnic composition of eligible jurors \n",
    "\n",
    "# We are going to look at these two distributions and compare them. \n",
    "# Column \"Eligible\": proportions in the eligible population \n",
    "# Column \"Actual\": proportions in those who reported for jury service \n",
    "\n",
    "\n",
    "jury = Table().with_columns(\n",
    "    'Ethnicity', make_array('Asian', 'Black', 'Latino', 'White', 'Other'),\n",
    "    'Eligible', make_array(0.15, 0.18, 0.12, 0.54, 0.01),\n",
    "    'Actual', make_array(0.26, 0.08, 0.08, 0.54, 0.04)\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compare:\n",
    "\n",
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What ethnicities were under-represented based on the bar chart above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Main question: If you select at random from blue distribution, you do not expect to get exactly blue distribution,\n",
    "#it will be off. Is the random selection off like a random sample would be off? Or is it off in some other way?\n",
    "\n",
    "#Let's quantify word \"OFF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of the difference between two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the table with a column of differences between proportions\n",
    "\n",
    "jury_with_diffs = jury.with_column(\n",
    "    'Difference', jury.column('Actual') - jury.column('Eligible')\n",
    ")\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Find the total in the last column by adding the positive differences and then adding the negative differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reason: (x1-y1) + (x2-y2) + (x3-y3) + (x4-y4) = 0\n",
    "#         (x1 + x2 + x3 + x4) - (y1 + y2 + y3 + y4) = 1 - 1 =0. \n",
    "\n",
    "# Therefore, averaging the distances does not make sense. \n",
    "\n",
    "# In fact, the sum of the positives, 0.14, is a measure of the distance between the two distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid the cancellation, we drop the negative signs\n",
    "\n",
    "jury_with_diffs = jury_with_diffs.with_column(\n",
    "    'Abs. Difference', np.abs(jury_with_diffs.column('Difference'))\n",
    ")\n",
    "\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then you add them up and divide by 2:\n",
    "#total variation distance between the two distributions\n",
    "#(back to slides)\n",
    "\n",
    "jury_with_diffs.column('Abs. Difference').sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes two arrays (representing distributions)\n",
    "#returns total variation distance between them\n",
    "\n",
    "def total_variation_distance (distribution_1, distribution_2):\n",
    "    '''Function that computes total variation distance between two arrays'''\n",
    "    return np.abs(distribution_1-distribution_2).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what is the purpose of this function?\n",
    "\n",
    "def table_tvd(table, label, other_label):\n",
    "    '''What does it do?'''\n",
    "    return total_variation_distance(table.column(label),table.column(other_label))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What answer do you expect?\n",
    "table_tvd(jury, 'Eligible', 'Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step back: What was our goal?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel_size = 1453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proportions_from_distribution method is defined for you\n",
    "panels_and_sample = proportions_from_distribution(jury, 'Eligible', panel_size)\n",
    "panels_and_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this function do? According to the documentation, \n",
    "\n",
    "#### proportions_from_distribution(table, label, sample_size, column_name='Random Sample')\n",
    "\n",
    "Adds a column named column_name containing the proportions of a random draw using the distribution in label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_and_sample.barh('Ethnicity')\n",
    "#what you see here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will simulate the total variation distance between the distribution of eligible jurors and a random sample from that distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tvd(panels_and_sample, 'Eligible', 'Random Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing, many times\n",
    "\n",
    "panel_size = 1453\n",
    "repetitions = 5000\n",
    "\n",
    "tvds = make_array()\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "\n",
    "    new_sample = proportions_from_distribution(jury, 'Eligible', panel_size)\n",
    "    tvds = np.append(tvds, table_tvd(new_sample, 'Eligible', 'Random Sample'))\n",
    "\n",
    "results = Table().with_column('TVD', tvds)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.hist(bins=np.arange(0, 0.2, 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is an empirical distribution of our statistic, the total variation distance.\n",
    "\n",
    "Back to slides for question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Employee Incomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'san_francisco_2015.csv' # 'http://inferentialthinking.com/notebooks/san_francisco_2015.csv'\n",
    "\n",
    "sf = Table.read_table(data).select(3, 11, 21)\n",
    "sf.set_format(2, NumberFormatter(0))\n",
    "sf = sf.where(2, are.above(10000))\n",
    "sf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.sort(2, descending  =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_bins = np.arange(0, 700000, 25000)\n",
    "sf.hist(2, bins=comp_bins, unit='dollar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppose we only have access to the sample:\n",
    "\n",
    "sample_from_population = sf.sample(200, with_replacement=False)  #unique workers \n",
    "sample_from_population.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_bins = np.arange(0, 700000, 25000)\n",
    "sample_from_population.hist(2, bins=comp_bins, unit='dollar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median compensation in the population? This is a parameter.\n",
    "Presumably, you would not know it.\n",
    "\n",
    "Use a statistic instead.\n",
    "Calculate the median of the sample, and use this sample median as an estimate for the population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(sample_from_population.column(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to slides for Variability of the Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_from_population.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(sample_from_population.column(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it does the bootstrap for you\n",
    "\n",
    "resample = sample_from_population.sample()\n",
    "resample.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample.select(\"Total Compensation\").hist(bins = np.arange(0, 700000, 25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(resample.column(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have another estimate for the population median. Do it again, a thousand times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_medians = []\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    resample = sample_from_population.sample()\n",
    "    median = np.median(resample.column(2))\n",
    "    resampled_medians.append(median)\n",
    "\n",
    "Table().with_column(\n",
    "    \"Resampled median\", resampled_medians\n",
    ").hist(unit='dollar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the two histograms above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the true population median? We have the luxury of being able to access the full population.\n",
    "# Normally, only have the sample (and resamples) from which to make a guess.\n",
    "\n",
    "np.median(sf.column(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Resampled median', resampled_medians).hist(unit='dollar')\n",
    "pop_median = np.median(sf.column(2))\n",
    "plots.scatter(pop_median, 0, color='red', s=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
